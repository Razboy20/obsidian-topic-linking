## Obsidian Topic Linking Plugin

This is a plugin for converting PDF files and web links to Markdown, and creating topics from Markdown content.

**Note:** This plugin is highly experimental, and can have unintended consequences on existing vaults.
Use with caution, and with test vaults where consequences are non-destructive.

The plugin is designed to help with common tasks associated with research. Often researchers will build large repositories of PDFs and links, not easily organised by a single folder or tagging system. The plugin uses the [stdlib](https://github.com/stdlib-js/stdlib) implementation of [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) (Latent Dirichlet  allocation) to scan Markdown text for common topics and keywords. It will produces a folder (by default, *Topics*) that contains an index and a series of individual files that link to documents relevant to related topics. 

The instructions below assume a default folder structure as follows:

  PDFs/ - a repository of PDF files
  Bookmarks/ - a repository of Markdown files containing external web links
  Generated/ - the location for Markdown files generated by *Extract PDF Content* and *Extract Web Links* commands
  Topics/ - the default location for topic files generated by the *Link Topics* command

Some of these folders can be configured under *Settings*. 

### Content Conversion Commands

Two commands convert PDF and web links to Markdown files located in a folder called *Generated/*.

The *Extract PDF Content* command uses *Obsidian*'s built-in PDF parser to convert a vault's PDFs to Markdown. The conversion is highly simplified and approximate, but results should still be legible. The command takes three options:
- *Overwrite PDF-generated content*: whether to overwrite existing Markdown files with the same name
- *Limit file number*: the maximum number of files to process (failing to set this can result in *Obsidian* running out of memory for large repositories)
- *Limit file size*: the maximum size of files to process. The meaning of 'file' (either the PDF source or generated Markdown) depends upon whether *Chunk file if size exceeds limit* is set. 
- *Chunk file if size exceeds limit*: if *Limit file size* is set, and Markdown files greater than this size are likely to be produced, the command will instead try to split the generated text across multiple smaller files. 

The *Extract Web Link-Generated Content* command scans a folder (the default is named *Bookmarks*) for web links - anything beginning with *http(s)://*. It also takes an *Overwrite* parameter:
- *Overwrite Web Links*: whether to overwrite existing Markdown files with the same name

### The *Link Topics* Command

The command at the heart of the plugin is *Link Topics*. This takes a pattern setting, *Topic File Pattern*, to scan Markdown files for topics. A number of other settings condition how those files are scanned, how the LDA model is trained, and how the results of the model are then formatted. Here are the general  parameters for the command:
- *Topic file pattern*: a *glob* style pattern for locating Markdown files for the model
- *Number of topics*: how many topics to generate
- *Number of words*: how many words to include for each topic
- *Stemming*: whether scanned tokens should be stemmed (e.g. 'capital' becomes 'capit')
- *Topic threshold*: what probability (between 0 and 1) a document must have to be relevant to a given topic

Other parameters condition how the Markdown files are sampled:
- *Fixed number of words*: select just a subset of each Markdown file, based on a fixed number of words
- *Percentage of total text*: select just a subset of each Markdown file, based on a percentage of the file's text (overriden by any non-zero value for *Fixed Number of Words*)
- *Randomise text*: if either *Fixed Number of Words* or *Percentage of Total Text* are selected, randomised whether these samples are drawn randomly.

The *Topic* folder can include either or both of the file pattern or current timestamp:
- *Include pattern in topic folder
- *Include timestamp in topic folder

Finally, the training parameters of the LDA model can be conditioned, as described in the [stdlib lda documentation](https://www.npmjs.com/package/@stdlib/nlp-lda):
- *LDA iterations*: Number of training iterations
- *LDA burn in*: Number of candidates initially discarded
- *LDA thin*: Number of candidates discarded at each subsequent iteration

 
### Sample use

An example use case of this plugin involves the following scenario: a collection of PDF files located in a *PDFs* folder, and another collection of web links located in a *Bookmarks* folder. Both PDFs and links cover a range of subjects or topics. 

1. Both *Extract PDF Content* and *Extract Web Links* commands are run, producing a series of Markdown files in the *Generated/* folder.
2. A number of the generated files include the term 'Data' in their file name, and this is a general subject  of interest. The *Topic File Pattern* Settings field is set to 'Generated/*Data*' (using a *glob*-style pattern).
3. Some of these files are books, containing more than 50K words. There are also a large number of files (~100) meeting this pattern. The *Fixed Number of Words* Settings field is set to *1,000*, to ensure topic mapping and linking executes in reasonable time. The *Randomise Text* field is also set to true, so that front matter (containing copyright and Table of Contents) is often ignored.
4. The *Link Topics* command is then executed, producing 10 topic files that map associated keywords and relevant documents. A *Topic Index* file links all of the files together, and includes a convenience check list of all documents matching the file pattern, which can be used to flag which documents have been read or cited.
 
<!-- 
### Integration with other plugins

...
-->

### Github link

See https://github.com/liammagee/obsidian-topic-linking-plugin

